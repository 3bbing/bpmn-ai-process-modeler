# --- Application ---
# Public name shown in titles/emails.
APP_NAME="BPMN AI Process Modeler"
# Current environment: `local`, `staging`, `production`; controls caching/error output.
APP_ENV=local
# 32-char encryption key. Generate per install via `php artisan key:generate`.
APP_KEY=
# Keep verbose errors only in local. Set `false` in production.
APP_DEBUG=true
# Base URL of the Laravel backend (with protocol). Local usually http://localhost; production e.g. https://api.bpmn.linara-apps.de.
APP_URL=http://localhost

# --- Logging ---
# Main log channel. `stack` = daily + stderr; change only if you use another logger.
LOG_CHANNEL=stack
# Destination for deprecation warnings. `null` = disabled.
LOG_DEPRECATIONS_CHANNEL=null
# Minimum log level. Production usually `info` or `warning`.
LOG_LEVEL=debug

# --- Database ---
# Database driver (`mysql`, `pgsql`, `sqlite`). Must match your DB.
DB_CONNECTION=mysql
# Database host. In Docker use the service name (e.g. mysql) instead of 127.0.0.1.
DB_HOST=127.0.0.1
# Database port.
DB_PORT=3306
# Database/schema name.
DB_DATABASE=bpmn_ai
# Database user with sufficient privileges.
DB_USERNAME=root
# Password for the DB user (never leave blank in production).
DB_PASSWORD=

# --- Infrastructure ---
# Broadcasting driver. Adjust only if using Echo/Pusher etc.
BROADCAST_DRIVER=log
# Cache backend. For multi-server setups prefer `redis` or `memcached`.
CACHE_DRIVER=file
# Main filesystem disk for uploads. Use `s3` or similar in production if needed.
FILESYSTEM_DISK=local
# Queue driver. `database` requires the jobs table migration.
QUEUE_CONNECTION=database
# Session storage. `file` is fine locally; use `redis` for scale.
SESSION_DRIVER=file
# Session lifetime in minutes.
SESSION_LIFETIME=120

# --- Sanctum / Frontend ---
# Comma-separated list of allowed frontend domains without protocol.
# Local: `localhost,localhost:5173`; production: `bpmn.yourapps.com` (plus subdomains).
SANCTUM_STATEFUL_DOMAINS=localhost
# Full URL of the SPA frontend. Local e.g. http://localhost:5173; production https://bpmn.yourapps.com.
FRONTEND_URL=http://localhost:5173

# --- OpenAI ---
# API key tied to your org/project.
OPENAI_API_KEY=
# Audio transcription model (e.g. gpt-4o-transcribe). Adjust as needed.
OPENAI_TRANSCRIPTION_MODEL=gpt-4o-transcribe
# Default LLM model for text completions. Change only if required.
OPENAI_LLM_MODEL=gpt-5.1
# Custom base URL if you go through a proxy/Azure OpenAI. Leave empty otherwise.
OPENAI_BASE_URI=
# Request timeout in seconds.
OPENAI_TIMEOUT=60
# Max automatic retries on errors.
OPENAI_MAX_RETRIES=3
# Delay between retries in milliseconds.
OPENAI_RETRY_DELAY_MS=200

# --- Uploads ---
# Max upload chunk size in bytes (here ~15 MB). Adjust to API limits if needed.
UPLOAD_MAX_CHUNK_BYTES=15728640
# Allowed MIME types for audio uploads. Extend if you support more formats.
AUDIO_ALLOWED_MIMES=audio/ogg,audio/webm

# --- Localization ---
# Default locale for translations. `de` or `en`.
APP_LOCALE=en
